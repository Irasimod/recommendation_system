{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Setup"
      ],
      "metadata": {
        "id": "bwu6KZkXC1J1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FmdIOzok5o9t"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from pyspark.sql import SparkSession\n",
        "import os\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "import numpy as np\n",
        "import sys\n",
        "import sqlite3\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import collect_list\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "fF1S-Mn0C6jw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5a5a79-3d56-4386-f9df-e32d55421d1a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset"
      ],
      "metadata": {
        "id": "cJHT7o8QCmsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"NestedJSONProcessing\").getOrCreate()\n",
        "\n",
        "def process_nested_folders(base_path):\n",
        "    final_df = None\n",
        "    # List all first-level folders\n",
        "    first_level_folders = [f for f in os.listdir(base_path) if os.path.isdir(os.path.join(base_path, f))]\n",
        "\n",
        "    # Iterate over each first-level folder\n",
        "    for folder in first_level_folders:\n",
        "        folder_path = os.path.join(base_path, folder)\n",
        "        print(f\"Processing folder: {folder_path}\")\n",
        "\n",
        "        # List all subfolders within this folder\n",
        "        subfolders = [os.path.join(folder_path, subfolder)\n",
        "                      for subfolder in os.listdir(folder_path)\n",
        "                      if os.path.isdir(os.path.join(folder_path, subfolder))]\n",
        "\n",
        "        # Read JSON files in all subfolders as a batch\n",
        "        for subfolder in subfolders:\n",
        "            print(f\"Processing subfolder: {subfolder}\")\n",
        "            json_files = os.path.join(subfolder, \"*.json\")\n",
        "\n",
        "            try:\n",
        "                # Load JSON files in the subfolder\n",
        "                chunk_df = spark.read.json(json_files)\n",
        "                final_df = chunk_df if final_df is None else final_df.union(chunk_df)\n",
        "                # Perform any processing you need\n",
        "                print(f\"Loaded {chunk_df.count()} rows from {subfolder}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing subfolder {subfolder}: {e}\")\n",
        "\n",
        "    return final_df"
      ],
      "metadata": {
        "id": "Jhkfhu5Mek6u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = process_nested_folders(\"/content/drive/MyDrive/lastfm_subset/lastfm_subset/A\")"
      ],
      "metadata": {
        "id": "CsImHLpN5xgM",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing"
      ],
      "metadata": {
        "id": "QfPiAOBxDkpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = data.drop('similars')\n",
        "def extract_tags(tags_column):\n",
        "    return [tag[0] for tag in tags_column]\n",
        "\n",
        "extract_tags_udf = udf(extract_tags, ArrayType(StringType()))\n",
        "df = df.withColumn(\"tags\", extract_tags_udf(col(\"tags\")))"
      ],
      "metadata": {
        "id": "-X3ATnxwlhgo",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create feature vectors"
      ],
      "metadata": {
        "id": "I4POCi2ID-BU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer(inputCol=\"tags\", outputCol=\"tags_vector\")\n",
        "vectorizer_model = count_vectorizer.fit(df)\n",
        "df = vectorizer_model.transform(df)"
      ],
      "metadata": {
        "id": "s-ICKhy6BRf2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "artist_indexer = StringIndexer(inputCol=\"artist\", outputCol=\"artist_index\")\n",
        "df = artist_indexer.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "uozdkePDGsNM",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"tags_vector\", \"artist_index\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df = assembler.transform(df)"
      ],
      "metadata": {
        "id": "W3tExbBrGwu5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "scaler_model = scaler.fit(df)\n",
        "df = scaler_model.transform(df)"
      ],
      "metadata": {
        "id": "lbviIWoJG90K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_df = df.select(\"track_id\", \"title\", \"scaled_features\").toPandas()\n",
        "features_matrix = np.array(pandas_df[\"scaled_features\"].tolist())\n",
        "\n",
        "similarity_matrix = cosine_similarity(features_matrix)"
      ],
      "metadata": {
        "id": "-EOIXI0nHwn2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query recommendations based on song id"
      ],
      "metadata": {
        "id": "vbhMtZroEYV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_songs(song_id, similarity_matrix, pandas_df, top_n=3):\n",
        "    song_idx = pandas_df[pandas_df[\"track_id\"] == song_id].index[0]\n",
        "    similarity_scores = list(enumerate(similarity_matrix[song_idx]))\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "    similar_songs = [\n",
        "        (pandas_df.iloc[idx][\"track_id\"], pandas_df.iloc[idx][\"title\"], score)\n",
        "        for idx, score in similarity_scores[1:top_n + 1]\n",
        "    ]\n",
        "    return similar_songs"
      ],
      "metadata": {
        "id": "Iq1Kegm3IEYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "song_id = \"TRAZJGD128F4289D2A\"  # Replace with the song ID you want to query\n",
        "similar_songs = get_similar_songs(song_id, similarity_matrix, pandas_df)\n",
        "print(similar_songs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsgLxAZxIFO-",
        "outputId": "16794913-78af-443f-9789-b7dec7b5b801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('TRAHBNZ128F92FC2A7', 'Uptown', 0.9979169735841514), ('TRAOMQN128F9328043', 'Life Of A Star', 0.9924641032573147), ('TRAIZHG128F934FE42', 'More Than Vocals (MTV)', 0.9913884825412685)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query recommendations based on user profile"
      ],
      "metadata": {
        "id": "ZNpD5MN1EiMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ],
      "metadata": {
        "id": "-eJ4pbgwJ4F1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/train_triplets.txt\"\n",
        "pandas_import = pd.read_csv(file_path, delimiter='\\t', header=None, names=['user_id', 'song_id', 'play_count'], nrows=1000)\n",
        "user_counts = pandas_import['user_id'].value_counts()\n",
        "pandas_import = pandas_import[pandas_import['user_id'].isin(user_counts[user_counts >= 20].index)]\n",
        "user_histories = spark.createDataFrame(pandas_import)"
      ],
      "metadata": {
        "id": "wRiNf9sloheU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter and join data"
      ],
      "metadata": {
        "id": "WeRe2Z_0dl-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_history = user_histories.filter(F.col(\"user_id\") == \"b80344d063b5ccb3212f76538f3d9e43d87dca9e\")\n",
        "user_history = user_history.withColumnRenamed(\"song_id\", \"track_id\")\n",
        "user_songs = user_history.join(df, on=\"track_id\", how=\"inner\")"
      ],
      "metadata": {
        "id": "92kGFdL7MzLr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate weights"
      ],
      "metadata": {
        "id": "6KS4hEGidqzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exploded_tags = user_songs.withColumn(\"tag\", F.explode(F.col(\"tags\")))\n",
        "tag_weights = exploded_tags.groupBy(\"tag\").agg(F.sum(\"play_count\").alias(\"tag_weight\"))\n",
        "artist_weights = user_songs.groupBy(\"artist\").agg(F.sum(\"play_count\").alias(\"artist_weight\"))\n",
        "combined_weights = tag_weights.withColumnRenamed(\"tag\", \"feature\").union(artist_weights.withColumnRenamed(\"artist\", \"feature\"))"
      ],
      "metadata": {
        "id": "ppWw2UUDYZ49"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_weight = combined_weights.agg(F.sum(\"tag_weight\").alias(\"total_weight\")).collect()[0][\"total_weight\"]\n",
        "normalized_weights = combined_weights.withColumn(\n",
        "    \"normalized_weight\", F.col(\"tag_weight\") / total_weight\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lyTPPs1lYaz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(inputCols=[\"normalized_weight\"], outputCol=\"user_profile\")\n",
        "assembler_model = assembler\n",
        "user_profile_vector = assembler_model.transform(normalized_weights)"
      ],
      "metadata": {
        "id": "E139RhwYYan0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_profile = user_profile_vector.select(\"user_profile\").collect()[0][\"user_profile\"].toArray().reshape(1, -1)\n",
        "similarity_scores = cosine_similarity(user_profile_vector, features_matrix).flatten()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "DwV_dS5DYaaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommended_songs(similarity_matrix, top_n=3):\n",
        "    similarity_scores = list(enumerate(similarity_matrix))\n",
        "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "    similar_songs = [\n",
        "        (pandas_df.iloc[idx][\"track_id\"], pandas_df.iloc[idx][\"title\"], score)\n",
        "        for idx, score in similarity_scores[1:top_n + 1]\n",
        "    ]\n",
        "    return similar_songs"
      ],
      "metadata": {
        "id": "dVfoo8KCoi0d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}